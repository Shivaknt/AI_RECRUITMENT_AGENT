# AI Recruitment Agent ðŸ¤–
### RAG Pipeline Â· Gemini LLM Â· Sentence Transformers Â· ChromaDB

---

## Stack

| Layer | Tool | Cost |
|---|---|---|
| LLM | Gemini 2.5 Flash | Free tier (generous) |
| Embeddings | Sentence Transformers `all-MiniLM-L6-v2` | **100% Free** (runs locally) |
| Vector DB | ChromaDB | **100% Free** (local folder) |
| PDF Extract | PyPDF2 | **100% Free** |


---

## Architecture

```
PDF / TXT Upload
    â”‚
    â–¼
extract_text()              PyPDF2 or plain read
    â”‚
    â–¼
chunk_text()                400-char chunks, 80-char overlap
    â”‚
    â–¼
MD5 hash check â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€ Already in ChromaDB? â†’ SKIP (free)
    â”‚  (cache miss)
    â–¼
embed_documents()           Sentence Transformers (local CPU/GPU)
    â”‚                       model: all-MiniLM-L6-v2, 384-dim
    â–¼
ChromaDB store              Saved to ./chroma_db/ (permanent)

â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

User Query (any section)
    â”‚
    â–¼
embed_query()               Same ST model (local, instant)
    â”‚
    â–¼
retrieve_chunks()           Top-5 cosine similar chunks
    â”‚
    â–¼
_call_gemini()              Gemini 1.5 Flash with context
    â”‚
    â–¼
Response to user
```

---

## Project Structure

```
recruitment-agent/
â”œâ”€â”€ app.py                  Flask routes
â”œâ”€â”€ resume_rag.py           Full RAG pipeline  â† main file
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ .env                    Gemini API key only
â”œâ”€â”€ chroma_db/              Auto-created vector store
â””â”€â”€ templates/
    â””â”€â”€ index.html          Frontend
```

---

## Setup

### 1. Get Gemini API key (free)
https://aistudio.google.com/app/apikey

### 2. Set .env
```
GEMINI_API_KEY=AIza...your_key_here
```

### 3. Install
```bash
pip install -r requirements.txt
```
> First run downloads the ST model (~80MB) once.
> Cached at `~/.cache/huggingface/` â€” never downloaded again.

### 4. Run
```bash
python app.py
# â†’ http://localhost:5000
```

---

## Test the pipeline from terminal

```bash
# Analyze a resume
python resume_rag.py path/to/resume.pdf "Data Scientist"

# List all stored resumes
python resume_rag.py
```

---

## Key behaviour

- **Same resume uploaded twice** â†’ ChromaDB already has it â†’ zero embedding cost
- **Embedding model** downloads once, then runs fully offline forever
- **chroma_db/** persists between server restarts â€” no data loss
- **All 5 app sections** share the same stored embeddings â€” no duplication
